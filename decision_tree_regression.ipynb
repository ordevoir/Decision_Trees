{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регресия\n",
    "### Генерация данных\n",
    "Для демонстрации решения задачи регрессии при помощи решающего дерева сгенерируем данные, в которых есть один целевой признак и один нецелевой. В этом случае имеем дело с задачей одномерной регрессии и решением будет некоторая линия. В файле scikit-learn_regression_example.ipynb решалась задача линейной регресси, в которой решением служилая прямая линия. Мы же для разнообразия сгенерируем данные, в которых зависимость целевого признака от нецелевого будет носить нелинейный характер. Пусть зависимость будет параболической."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `np.random.seed()` позволяет установить начальное состояние генератора случайных чисел, что позволяет получить одни и те же результаты при повторном запуске программы. Если вы используете модуль `np.random` без установки начального состояния, то каждый раз, когда вы запускаете программу, вы будете получать разные случайные числа.\n",
    "\n",
    "Функция `np.random.rand()` создает массив заданной формы, содержащий случайные значения, равномерно распределенные между 0 и 1. Если не задать форму в аргументах функции, то вместо массива будет возвращено число. \n",
    "\n",
    "Функция `np.random.randn()` создает массив заданной формы, содержащий случайные значения, c нормальным распределеннием (среднее значение равно 0, стандартное отклонение равно 1). Если не задать форму в аргументах функции, то вместо массива будет возвращено число. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic training set + noise\n",
    "np.random.seed(42)\n",
    "n = 200                     # число точек\n",
    "\n",
    "# генерация значений нецелевого признака\n",
    "X = np.random.rand(n, 1)    \n",
    "print(f\"{X.shape = }\")\n",
    "\n",
    "# генерация значений целевого признака\n",
    "y = 4 * (X - 0.5) ** 2\n",
    "print(f\"{y.shape = }\")\n",
    "\n",
    "# добавления шума\n",
    "y = y + np.random.randn(n, 1) / 10\n",
    "\n",
    "# визуализация\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение деревье различной глубины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=1)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(tree_reg1, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plot_tree(tree_reg2, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Визуализация линии регрессии\n",
    "Напишем функцию, которая будет визуализировать точки данных и решающую линию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_predictions(model, X, y, axes=[0, 1, -0.2, 1.2]):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
    "    y_pred = model.predict(x1)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel('$x_1$', fontsize=18)\n",
    "    plt.ylabel('$y$', fontsize=18, rotation=0)\n",
    "    plt.plot(X, y, \"b.\")    \n",
    "    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=\"$\\hat y$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "# первый рисунок\n",
    "plt.sca(axes[0])\n",
    "plot_regression_predictions(tree_reg1, X, y)\n",
    "plt.legend(loc='upper center', fontsize=18)\n",
    "plt.title('max_depth=1', fontsize=14)\n",
    "# второй рисунок\n",
    "plt.sca(axes[1])\n",
    "plot_regression_predictions(tree_reg2, X, y)\n",
    "plt.title('max_depth=2', fontsize=14)\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg3 = DecisionTreeRegressor(max_depth=3)\n",
    "tree_reg4 = DecisionTreeRegressor(max_depth=4)\n",
    "tree_reg3.fit(X, y)\n",
    "tree_reg4.fit(X, y)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "# первый рисунок\n",
    "plt.sca(axes[0])\n",
    "plot_regression_predictions(tree_reg3, X, y)\n",
    "plt.legend(loc='upper center', fontsize=18)\n",
    "plt.title('max_depth=3', fontsize=14)\n",
    "# второй рисунок\n",
    "plt.sca(axes[1])\n",
    "plot_regression_predictions(tree_reg4, X, y)\n",
    "plt.title('max_depth=4', fontsize=14)\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg5 = DecisionTreeRegressor(max_depth=5)\n",
    "tree_reg6 = DecisionTreeRegressor()\n",
    "tree_reg5.fit(X, y)\n",
    "tree_reg6.fit(X, y)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "# первый рисунок\n",
    "plt.sca(axes[0])\n",
    "plot_regression_predictions(tree_reg5, X, y)\n",
    "plt.legend(loc='upper center', fontsize=18)\n",
    "plt.title('max_depth=5', fontsize=14)\n",
    "# второй рисунок\n",
    "plt.sca(axes[1])\n",
    "plot_regression_predictions(tree_reg6, X, y)\n",
    "plt.title('max_depth=15', fontsize=14)\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg6.get_depth()   # глубина"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение и регуляризация\n",
    "Деревья решений почти не делают предположений о тренировочных данных (в отличие от, например, линейных моделей, которые предполагают, что данные являются линейными). Если не ставить ограничения, дерево подстраивается к данным как можно ближе, приводя к переобучению. Такие модели часто называются **непараметрическими моделями**, не от того, что в модели нет параметров (их может быть даже много), а от того, что число этих параметров заранее не определено, и структура модели может свободно прилегать к данным. В противоположность этому, **параметрические модели**, такие как линейные модели, имеют предопределенное число параметров, так что степень свободы ограничена, что снижает риск переобучения (хотя повышает риск недообучения).<br>\n",
    "\n",
    "\n",
    "**Переобучение** (*overfitting*) - это проблема в машинном обучении, когда модель слишком точно подстраивается под тренировочные данные вместо того, чтобы находить общие закономерность, которая позволила бы прогнозировать результат на новых данных, которых она ранее не видела. При переобучении модель становится слишком сложной и начинает запоминать шум и случайности в тренировочных данных. Как результат, модель производит очень низкую ошибку на тренировочных данных, но плохо справляется с предсказанием на новых данных.\n",
    "\n",
    "**Регуляризацией** называются методы, которые применяются для предотвращения переобучения, которые помогают ограничить сложность модели и улучшить ее обобщающую способность.\n",
    "\n",
    "В случае с деревьями решений есть ряд регуляризирующих гиперпараметров, позволяющих избежать переобучение путем ограничения степеней свободы дерева решений. Регуляризующие гиперпараметры дерева решений зависят от алгоритма построения, но во всяком случае есть возможность ограничить глубину дерева гиперпараметром `max_depth` (по умолчанию стоит значение `None`, что означает неограниченность). <br>\n",
    "Классы `DecisionTreeClassifier` и `DecisionTreeRegressor` имеет несколько других гиперпараметров, ограничивающих форму дерева:<br>\n",
    "`min_samples_leaf` - минимальное число экземпляров в узле, необходимых для дальнейшего разбиения<br>\n",
    "`min_weight_leaf` - минимальное число экземпляров, допустимых в узле<br>\n",
    "`max_leaf_nodes` - максимальное число листов<br>\n",
    "`max_features` - максимальное число признаков, оцениваемых при разделении узла<br>\n",
    "Увеличение **min** гиперпараметров и уменьшение **max** гиперпараметров регуляризирует модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg7 = DecisionTreeRegressor(max_depth=7)  \n",
    "tree_reg7_reg1 = DecisionTreeRegressor(max_depth=7, min_samples_leaf=10)\n",
    "tree_reg7.fit(X, y)\n",
    "tree_reg7_reg1.fit(X, y)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "# первый рисунок\n",
    "plt.sca(axes[0])\n",
    "plot_regression_predictions(tree_reg7, X, y)\n",
    "plt.legend(loc='upper center', fontsize=18)\n",
    "plt.title('No restriction', fontsize=14)\n",
    "# второй рисунок\n",
    "plt.sca(axes[1])\n",
    "plot_regression_predictions(tree_reg7_reg1, X, y)\n",
    "plt.title('min_samples_leaf=10', fontsize=14)\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg7_reg2 = DecisionTreeRegressor(max_depth=7, max_leaf_nodes=12)\n",
    "tree_reg7_reg2.fit(X, y)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "# первый рисунок\n",
    "plt.sca(axes[0])\n",
    "plot_regression_predictions(tree_reg7, X, y)\n",
    "plt.legend(loc='upper center', fontsize=18)\n",
    "plt.title('No restriction', fontsize=14)\n",
    "# второй рисунок\n",
    "plt.sca(axes[1])\n",
    "plot_regression_predictions(tree_reg7_reg2, X, y)\n",
    "plt.title('min_samples_leaf=10', fontsize=14)\n",
    "plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
